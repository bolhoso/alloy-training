livedebugging {
  enabled = true
}

//Section 1

logging {
  format = "logfmt"
  level = "debug"
  write_to = [loki.relabel.alloy_logs.receiver]
}


loki.relabel "alloy_logs" {
  forward_to = [loki.write.mythical.receiver]

  // rules are executed in the order they written
  rule {
  // it's an upsert, find the group label and replace the value. Add the value if it doesn't exsist
    target_label = "group"
    replacement = "infrastructure"
  }

  rule {
    target_label = "service"
    replacement = "alloy"
  }
}

loki.write "mythical" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
  }
}

//Section 2
discovery.http "service_discovery" {
  url = "http://service-discovery/targets.json"
  refresh_interval = "2s"
}

prometheus.scrape "infrastructure" {
  scrape_interval = "2s"
  scrape_timeout = "2s"

  targets = discovery.http.service_discovery.targets
  forward_to = [prometheus.remote_write.mimir.receiver]
}

prometheus.remote_write "mimir" {
  endpoint {
    url = "http://mimir:9009/api/v1/push"
  }
}

//Section 3
prometheus.exporter.postgres "mythical" {
  data_source_names = ["postgresql://postgres:mythical@mythical-database:5432/postgres?sslmode=disable"]
}

prometheus.scrape "postgres" {
  scrape_interval = "2s"
  scrape_timeout = "2s"

  targets = prometheus.exporter.postgres.mythical.targets
  forward_to = [prometheus.relabel.postgres.receiver]
}

prometheus.relabel "postgres" {
  forward_to = [prometheus.remote_write.mimir.receiver]

  rule {
    target_label = "group"
    replacement = "infrastructure"
  }

  rule {
    target_label = "service"
    replacement = "alloy"
  }

  //What we have: postgres_table_rows_count{instance="postgresql://mythical-database:5432/postgres"}
  //What we want: postgres_table_rows_count{instance="mythical-database:5432/postgres"}

  rule {
    // Replace the targeted label.
    action = "replace"

    // The label we want to replace is 'instance'.
    target_label = "instance"

    // Look in the existing 'instance' label for a value that matches the regex.
    source_labels = ["instance"]
    regex = "^postgresql://(.+)"

    // Use the first value found in the 'instance' label that matches the regex as the replacement value.
    replacement = "$1"
  }
}

//Section 4
prometheus.scrape "mythical" {
    scrape_interval = "2s"
    scrape_timeout  = "2s"

    targets    =  [
        {"__address__" = "mythical-server:4000",    group = "mythical", service = "mythical-server"},
        {"__address__" = "mythical-requester:4001", group = "mythical", service = "mythical-requester"},
    ]
    forward_to =  [prometheus.write.queue.experimental.receiver]
}

prometheus.write.queue "experimental" {
    endpoint "mimir" {
        url = "http://mimir:9009/api/v1/push"
    }
}

//Section 5
otelcol.receiver.otlp "otlp_receiver" {
    grpc {
        endpoint = "0.0.0.0:4317"
    }
    http {
        endpoint = "0.0.0.0:4318"
    }
    output {
        traces = [
            otelcol.processor.batch.default.input,
            otelcol.connector.spanlogs.autologging.input,
        ]
    }
}

otelcol.processor.batch "default" {
    output {
        traces = [
            otelcol.exporter.otlp.tempo.input,
        ]
    }

    send_batch_size = 1000
    send_batch_max_size = 2000

    timeout = "2s"
}

otelcol.exporter.otlp "tempo" {
    client {
        endpoint = "tempo:4317"

        // This is a local instance of Tempo, so we can skip TLS verification
        tls {
            insecure             = true
            insecure_skip_verify = true
        }
    }
}


//Section 6
// Alloy is like a "minimal" loki server
loki.source.api "mythical" {
     http {
        listen_address = "0.0.0.0"
        listen_port    = "3100"
    }
    forward_to = [loki.process.mythical.receiver]
}

loki.process "mythical" {
    stage.static_labels {
        values = {
           // just set this label
           service = "mythical",
                 lelek = "1234",
        }
    }
   stage.regex {
        expression=`^.*?loggedtime=(?P<loggedtime>\S+)`
   }

   stage.timestamp {
        source = "loggedtime"
        format = "2006-01-02T15:04:05.000Z07:00" // 0000-00-00T00:00:000Z00:00
    }

    forward_to = [loki.write.mythical.receiver]
}

//Section 7
otelcol.connector.spanlogs "autologging" {
    roots = true
    spans = true
    processes = false

    span_attributes = ["http.method", "http.status_code", "http.target"]
    //these are the span attributes that I would like to include in the logs

    output {
      logs = [otelcol.exporter.loki.autologging.input]
    }
}

otelcol.exporter.loki "autologging" {
    forward_to = [loki.process.autologging.receiver]
}

// The Loki processor allows us to accept a Loki-formatted log entry and mutate it into
// a set of fields for output.
loki.process "autologging" {
    stage.json {
       expressions = {"body" = ""}
    }

    stage.output {
       source = "body"
    }

    stage.logfmt {
        mapping = {
            http_method_extracted = "http.method", // ex will look for anythingi nthe log like "http.method=GET"
            http_status_code_extracted = "http.status_code",
            http_target_extracted = "http.target",

        }
    }

    stage.labels {
        values = {
            method = "http_method_extraced",
            status = "http_status_code_extracted",
            target = "http_target_extracted",
        }
    }

    forward_to = [loki.write.mythical.receiver]
}
